{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Homework 4\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "This assignment will continue to use the American Community Survey (ACS) from the US Census.\n",
        "You will need to refer to the documentation to know what the ACS variable names mean. You can find a copy of the codebook in the [Lab 4 folder on Google Drive](https://drive.google.com/drive/u/0/folders/1jkY0mTxBhwOvvCJE_CJ3LWiOr_9V1ojZ)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "acs = pd.read_csv(\"./pums_short.csv.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1: Working with missing data\n",
        "\n",
        "### Q1.a\n",
        "\n",
        "In the previous lab we counted the number of missing values for the `\"RNTP\"` column using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "acs[\"RNTP\"].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Repeat for the `\"VALP\"` column. (If you want, you can compute both totals simultaneously.)\n",
        "\n",
        "Print out the total number of rows in the `acs` table. What do you notice about the total number of rows and the sum of the missing values for these two columns?\n",
        "\n",
        "\n",
        "\n",
        "### Q1.b\n",
        "\n",
        "Write a single line of code that proves that 100% of observations are missing either the `\"VALP\"` or `\"RNTP\"` measurements.\n",
        "\n",
        "\n",
        "### Q1.c\n",
        "\n",
        "The `.dropna()` method has a `subset = ['column1', 'column2']` argument that allows you to indicate which columns your want to use to control how rows are dropped from the result.\n",
        "\n",
        "Create a table called `owners` that only includes households that have non-missing `\"VALP\"` entries. Print out the number of rows in this table and verify it matches the number of observations with *non-missing* `\"VALP\"` entries in `acs`. Hint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hint = pd.Series([True, False, False, True])\n",
        "~ hint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q1.d\n",
        "\n",
        "Using the `owners` table, what **proportion** of rows are missing `\"HINCP\"` values?\n",
        "\n",
        "Find the median value of the non-missing values (hint: built in Panadas methods automatically drop missing values).\n",
        "\n",
        "Using the `.fillna(VALUE, inplace = TRUE)` method, update the `\"HINCP\"` column of the `owners` table by making any missing values equal to median of the non-missing values.\n",
        "\n",
        "Verify by showing that all of the values are not missing for `\"HINCP\"`.\n",
        "\n",
        "\n",
        "\n",
        "### Q1.e\n",
        "\n",
        "Repeat the above steps to create a table `renters` that contains only rows for people who are renting (have non-missing `RNTP` values) and median impute any missing `HINCP` values.\n",
        "\n",
        "For both `owners` and `renters` compute the following quantities for the \"HINCP\" column.\n",
        "- mean\n",
        "- median\n",
        "- IQR\n",
        "- standard deviation\n",
        "\n",
        "Which group has the higher location values? Which group has more spread? Comment briefly on what this means.\n",
        "\n",
        "\n",
        "\n",
        "## Question 2: More on distributions\n",
        "\n",
        "### Q2.a Distributions of number of people in the household\n",
        "\n",
        "Create a histogram of the number of people in the household (`NP`) for the `acs` data. Use the `bins` argument to create a histogram with 20 bins. Briefly discuss the location, spread, and skew of the distribution.\n",
        "\n",
        "### Q2.b Summaries of `NP`\n",
        "\n",
        "Check your answers to the previous question by computing the mean, median, IQR, standard deviation, quantile skewness using the 0.25 and 0.75 quantile, and the coefficient of skewness of the `NP` column.\n",
        "\n",
        "### Q2.c Comparing conditional distribution of NP for owners and renters\n",
        "\n",
        "Create a side-by-side boxplot of the number of people in the household for owners and renters. What do you notice about the distributions of the number of people in the household for owners and renters?\n",
        "\n",
        "### Q2.d Effect size of the difference in means\n",
        "\n",
        "Compute the effect size of the difference in means of the number of people in the household for owners and renters. Use the formula for Cohen's $d$\n",
        "\n",
        "$$d = \\frac{\\bar X_1 - \\bar X_2}{S_p}$$\n",
        "\n",
        "where $\\bar X_1$ and $\\bar X_2$ are the means of the two groups and $S_p$ is the pooled standard deviation.\n",
        "\n",
        "Using the following table of effect sizes, how would you interpret the effect size of the difference in means of the number of people in the household for owners and renters?\n",
        "\n",
        "| Effect size | Interpretation |\n",
        "|-------------|-----------------|\n",
        "| (0, 0.2]    | Small           |\n",
        "| (0.2, 0.5]  | Medium          |\n",
        "| (0.5, 0.1]  | Large           |\n",
        "| (1, 2]      | Very large      |\n",
        "\n",
        "\n",
        "\n",
        "## Question 3: More on means and medians\n",
        "\n",
        "For this problem, we will investigate some theoretical properties of means and medians.\n",
        "\n",
        "### Q3.a\n",
        "\n",
        "We have already seen that the mean is the unique point $\\bar X$ that makes $\\sum_{i=1}^n (X_i - \\bar X) = 0$. While we didn't introduce it as such, it is also the case that $\\bar X$ is the point that **minimizes** $\\sum_{i=1}^n (X_i - \\bar X)^2$, the sum of squared deviations.\n",
        "\n",
        "Using the `HINCP` column of the `acs` data, demonstrate that the sum of squared deviations from the mean is less than the sum of squared deviations from the median ($\\sum_{i=1}^n (X_i - \\tilde X)^2$).\n",
        "\n",
        "Recall that `x**2` is how we square things in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q3.b\n",
        "\n",
        "Now, using $\\bar X$ and $\\tilde X$, compute the **sum of absolute distances**, $\\sum_{i=1}^n | X_i - \\bar X |$ and $\\sum_{i=1}^n |X_i - \\tilde X|$. Recall the `.abs()` method can compute the absolute value of a series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q3.c\n",
        "\n",
        "While we are not rising to the level of a mathematical proof, what do these result suggest about which type of measure of location would minimize the sum of absolute differences?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/mark/Documents/Professional/Teaching/umich/data-science-101-materials/env/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}